{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、写在前面\n",
    "\n",
    "### 1.1 任务介绍\n",
    "\n",
    "在解决智能客服场景中的语义理解问题时，我们常常需要判断两个自然语言问句在语义上是否等价。为此，我们希望引入轻量级的小规模语言模型（LLM）来实现这一目标，并在多个应用场景中进行充分的量化评估，以期在最小计算开销的前提下满足业务需求。\n",
    "\n",
    "我们选用了 **ERNIE-4.5-0.3B-Base** 模型作为基础，该模型仅有 0.3B 参数量，属于基础预训练版本，具备极致轻量化和快速推理能力，非常适合部署在资源受限的场景中。\n",
    "\n",
    "借助 FastDeploy，我们进一步支持了多种量化推理方式，包括 INT8、INT4 和 2-bit 等不同精度设置，能够对模型权重、激活值以及 KVCache 三类张量分别进行精度优化，全面适配低成本、低时延和长上下文等不同推理场景的需求。\n",
    "\n",
    "以下是不同量化方案的简要对比：\n",
    "\n",
    "| 量化方法 | 权重精度 | 激活精度 | KVCache 精度 | 在线/离线 | 支持硬件 |\n",
    "|----------|-----------|-----------|----------------|-------------|------------|\n",
    "| WINT8    | **INT8**  | BF16      | BF16           | 在线        | GPU, XPU   |\n",
    "| WINT4    | **INT4**  | BF16      | BF16           | 在线        | GPU, XPU   |\n",
    "| WINT2    | **2 Bits**| BF16      | BF16           | 离线        | GPU        |\n",
    "\n",
    "接下来，我们将在原始模型（BASE）及其 INT8、INT4、INT2 量化版本上，开展多维度的应用场景评测，深入分析不同精度配置下的性能与效果表现，为实际部署提供数据支撑和决策依据。\n",
    "\n",
    "### 1.2 数据介绍\n",
    "\n",
    "其中，用以评测的数据集：\n",
    "\n",
    "* 百度DuQM测试集\n",
    "\n",
    "通过对搜索问答场景中的原始问题进行替换、插入等操作，并过滤掉真实场景中未出现过的问题，保证扰动后问题的自然性和流畅性，然后进行人工筛选和语义匹配标注，得到最终的评测集。\n",
    "\n",
    "* OPPO小布对话短文本测试集\n",
    "\n",
    "采样自OPPO语音助手小布的真实对话场景数据，进行人工筛选和语义匹配标注，得到最终的评测集。\n",
    "\n",
    "给定一组问题对，判断问题对在语义上是否匹配(等价)，例如：\n",
    "\n",
    "|类型|问题1|问题2|标签|\n",
    "|-|-|-|-|\n",
    "|匹配|胎儿什么时候入盆|胚胎什么时候入盆|1|\n",
    "|不匹配|人民币怎么换港币|港币怎么换人民币|0|\n",
    "\n",
    "### 1.3 评测指标\n",
    "\n",
    "本次评测采用的评价指标为宏平均准确率（Macro-Accuracy），即先求得14个维度的准确率（Accuracy），然后对所有维度的准确率求平均(Macro-Averaging)，\n",
    "\n",
    "详细评分: $Acc_{macro} = \\frac{\\sum_{i=1}^N Acc_i}{N}$\n",
    "\n",
    "其中，$Acc_i= \\frac{TP_i + TN_i}{TP_i + TN_i + FP_i + FN_i}$, *TP=True positive, TN=True negative, FP=False positive, FN=False negative*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、准备工作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 文本长度\n",
    "\n",
    "为避免文本长度受限，我们查看以下拟跑批文本的最长文本长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T12:50:45.859084Z",
     "iopub.status.busy": "2025-12-31T12:50:45.858802Z",
     "iopub.status.idle": "2025-12-31T12:50:45.896176Z",
     "shell.execute_reply": "2025-12-31T12:50:45.895363Z",
     "shell.execute_reply.started": "2025-12-31T12:50:45.859064Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX 97\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_l = 0\n",
    "with open(\"test/test.tsv\", \"r\") as f:\n",
    "    for i in f:\n",
    "        l = len(i)\n",
    "        if l > max_l:\n",
    "            max_l = l\n",
    "print(f\"MAX {max_l}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 相关脚本\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **0.init.sh/环境初始化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T12:51:56.355656Z",
     "iopub.status.busy": "2025-12-31T12:51:56.355388Z",
     "iopub.status.idle": "2025-12-31T12:51:56.581964Z",
     "shell.execute_reply": "2025-12-31T12:51:56.581036Z",
     "shell.execute_reply.started": "2025-12-31T12:51:56.355637Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "pip install pandarallel\r\n",
      "\r\n",
      "clear\r\n",
      "path=/home/aistudio/data/models\r\n",
      "model=ERNIE-4.5-0.3B-Base-Paddle\r\n",
      "\r\n",
      "echo $model\r\n",
      "rm -rf $path/$model\r\n",
      "aistudio download --model PaddlePaddle/$model --local_dir $path/$model\r\n",
      "ls -l $path/$model\r\n"
     ]
    }
   ],
   "source": [
    "! cat 0.init.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **1.server-X.sh/启动服务**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T12:52:01.737139Z",
     "iopub.status.busy": "2025-12-31T12:52:01.736877Z",
     "iopub.status.idle": "2025-12-31T12:52:01.960655Z",
     "shell.execute_reply": "2025-12-31T12:52:01.959639Z",
     "shell.execute_reply.started": "2025-12-31T12:52:01.737118Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "clear\r\n",
      "path=/home/aistudio/data/models\r\n",
      "model=ERNIE-4.5-0.3B-Base-Paddle\r\n",
      "\r\n",
      "python -m fastdeploy.entrypoints.openai.api_server --model $path/$model --port 8180 --metrics-port 8181 --engine-worker-queue-port 8182 --max-model-len 3072 --max-num-seqs 128\r\n",
      "\r\n",
      "clear\r\n",
      "path=/home/aistudio/data/models\r\n",
      "model=ERNIE-4.5-0.3B-Base-Paddle\r\n",
      "\r\n",
      "python -m fastdeploy.entrypoints.openai.api_server --model $path/$model --port 8180 --metrics-port 8181 --engine-worker-queue-port 8182 --max-model-len 3072 --max-num-seqs 128 --quantization wint2\r\n",
      "\r\n",
      "clear\r\n",
      "path=/home/aistudio/data/models\r\n",
      "model=ERNIE-4.5-0.3B-Base-Paddle\r\n",
      "\r\n",
      "python -m fastdeploy.entrypoints.openai.api_server --model $path/$model --port 8180 --metrics-port 8181 --engine-worker-queue-port 8182 --max-model-len 3072 --max-num-seqs 128 --quantization wint4\r\n",
      "\r\n",
      "clear\r\n",
      "path=/home/aistudio/data/models\r\n",
      "model=ERNIE-4.5-0.3B-Base-Paddle\r\n",
      "\r\n",
      "python -m fastdeploy.entrypoints.openai.api_server --model $path/$model --port 8180 --metrics-port 8181 --engine-worker-queue-port 8182 --max-model-len 3072 --max-num-seqs 128 --quantization wint8\r\n"
     ]
    }
   ],
   "source": [
    "! cat 1.server*.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **2.run.py/模型调用**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import openai\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.system(\"clear\")\n",
    "\n",
    "# Import\n",
    "from pandarallel import pandarallel\n",
    "# Initialization\n",
    "pandarallel.initialize(nb_workers=64, progress_bar=True)\n",
    "\n",
    "host = \"0.0.0.0\"\n",
    "port = \"8180\"\n",
    "client = openai.Client(base_url=f\"http://{host}:{port}/v1\", api_key=\"null\")\n",
    "\n",
    "_system = {\n",
    "    \"role\": \"system\", \n",
    "    \"content\": \"\"\"\n",
    "你是一个自然语言处理专家，现在需要进行问题匹配，不匹配返回0，匹配返回1，\n",
    "\n",
    "输入：\n",
    "{\"A\": \"婴儿吃什么蔬菜好\", \"B\": \"婴儿吃什么绿色蔬菜好\"}\n",
    "\n",
    "输出：\n",
    "{\"result\": 0}\n",
    "\n",
    "严格按照输出的json格式。\n",
    "\"\"\"\n",
    "}\n",
    "_E1, _E2 = 0, 0\n",
    "\n",
    "\n",
    "def get(_c):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"null\",\n",
    "        messages=[\n",
    "            _system, \n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": json.dumps(_c, ensure_ascii=False)\n",
    "            }\n",
    "        ],\n",
    "        stream=False,\n",
    "        response_format={\n",
    "            \"type\": \"json_object\",\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"result\": {\"type\": \"int\"}\n",
    "                },\n",
    "                \"required\": [ \n",
    "                    \"result\"\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        _j = json.loads(\n",
    "            response.choices[0].message.content.replace(\"`\",\"\").replace(\"json\",\"\")\n",
    "        )\n",
    "        _r = int(_j.get(\"result\", 0))\n",
    "    except Exception as e:\n",
    "        print(f\"\\n \\033[1;36m ERROR:\\033[0m \\n{response.choices[0].message.content[:100]}\\n{e}\", )\n",
    "        _r = 0\n",
    "    return _r if _r == 0 else 1\n",
    "\n",
    "\n",
    "t = \"\"\"\n",
    "{\"A\": \"婴儿吃什么蔬菜好\", \"B\": \"婴儿吃什么绿色蔬菜好\"}\n",
    "\"\"\"\n",
    "print(f\"\"\"Test \"{get(t)}\".\\n\"\"\")\n",
    "# raise \"Test\"\n",
    "\n",
    "\n",
    "data = pd.read_csv(\n",
    "    \"test/test.tsv\", \n",
    "    sep=\"\\t\", header=None,\n",
    "    names=[\"A\", \"B\"],\n",
    ")\n",
    "print(data.shape)\n",
    "\n",
    "data[\"text\"] = [\n",
    "    {\"A\": f\"{_1}\", \"B\": f\"{_2}\"}\n",
    "    for _1, _2 in zip(data[\"A\"], data[\"B\"])\n",
    "]\n",
    "data[\"result\"] = data[\"text\"].parallel_apply(get)\n",
    "print(data)\n",
    "print(data[\"result\"].value_counts())\n",
    "\n",
    "with open(\"test/predict.csv\", \"w\") as f:\n",
    "    for i in data[\"result\"]:\n",
    "        f.write(f\"{i}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **3.moni.py/运行监控**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import psutil\n",
    "from pynvml import *\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "\n",
    "class ResourceMonitor:\n",
    "    def __init__(self):\n",
    "        nvmlInit()\n",
    "        self.handle = nvmlDeviceGetHandleByIndex(0)\n",
    "        \n",
    "    def get_stats(self):\n",
    "        cpu = psutil.cpu_percent(interval=0.1)\n",
    "        mem = psutil.virtual_memory().percent\n",
    "        gpu = nvmlDeviceGetUtilizationRates(self.handle).gpu\n",
    "        return {\"CPU\": cpu, \"Mem\": mem, \"GPU\": gpu}\n",
    "\n",
    "\n",
    "monitor = ResourceMonitor()\n",
    "process = subprocess.Popen(\"python 2.run.py > 2.run.log\", shell=True)\n",
    "\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        stats = monitor.get_stats()\n",
    "        print(f\"CPU:\\t{stats['CPU']:.2f}%\\t|Mem:\\t{stats['Mem']:.2f}%\\t|GPU:\\t{stats['GPU']:.2f}%\")\n",
    "        if process.poll() is not None: break\n",
    "        time.sleep(60)\n",
    "finally:\n",
    "    process.terminate()\n",
    "    nvmlShutdown()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、开始运行\n",
    "\n",
    "其中，启动服务部分建议在终端另行执行。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 ERNIE-4.5-0.3B-Base\n",
    "\n",
    "* **启动服务**\n",
    "\n",
    "```shell\n",
    "sh 1.server-base.sh &\n",
    "```\n",
    "\n",
    "* **开始评测**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T12:52:14.706898Z",
     "iopub.status.busy": "2025-12-31T12:52:14.706611Z",
     "iopub.status.idle": "2025-12-31T12:52:14.927741Z",
     "shell.execute_reply": "2025-12-31T12:52:14.926717Z",
     "shell.execute_reply.started": "2025-12-31T12:52:14.706878Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "clear\r\n",
      "path=/home/aistudio/data/models\r\n",
      "model=ERNIE-4.5-0.3B-Base-Paddle\r\n",
      "\r\n",
      "python -m fastdeploy.entrypoints.openai.api_server --model $path/$model --port 8180 --metrics-port 8181 --engine-worker-queue-port 8182 --max-model-len 3072 --max-num-seqs 128\r\n"
     ]
    }
   ],
   "source": [
    "! cat 1.server-base.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T10:46:23.822435Z",
     "iopub.status.busy": "2025-12-31T10:46:23.822197Z",
     "iopub.status.idle": "2025-12-31T11:05:26.701681Z",
     "shell.execute_reply": "2025-12-31T11:05:26.700879Z",
     "shell.execute_reply.started": "2025-12-31T10:46:23.822416Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU:\t7.30%\t|Mem:\t21.90%\t|GPU:\t0.00%\r\n",
      "CPU:\t8.90%\t|Mem:\t22.00%\t|GPU:\t44.00%\r\n",
      "CPU:\t5.60%\t|Mem:\t22.00%\t|GPU:\t45.00%\r\n",
      "CPU:\t6.50%\t|Mem:\t22.00%\t|GPU:\t43.00%\r\n",
      "CPU:\t7.70%\t|Mem:\t22.00%\t|GPU:\t43.00%\r\n",
      "CPU:\t7.00%\t|Mem:\t22.00%\t|GPU:\t43.00%\r\n",
      "CPU:\t15.90%\t|Mem:\t22.00%\t|GPU:\t40.00%\r\n",
      "CPU:\t5.70%\t|Mem:\t22.00%\t|GPU:\t44.00%\r\n",
      "CPU:\t6.50%\t|Mem:\t22.00%\t|GPU:\t39.00%\r\n",
      "CPU:\t6.10%\t|Mem:\t22.00%\t|GPU:\t46.00%\r\n",
      "CPU:\t9.30%\t|Mem:\t22.00%\t|GPU:\t41.00%\r\n",
      "CPU:\t8.60%\t|Mem:\t22.00%\t|GPU:\t44.00%\r\n",
      "CPU:\t6.10%\t|Mem:\t22.00%\t|GPU:\t40.00%\r\n",
      "CPU:\t7.90%\t|Mem:\t22.00%\t|GPU:\t40.00%\r\n",
      "CPU:\t6.30%\t|Mem:\t22.00%\t|GPU:\t39.00%\r\n",
      "CPU:\t6.50%\t|Mem:\t22.00%\t|GPU:\t43.00%\r\n",
      "CPU:\t7.50%\t|Mem:\t22.00%\t|GPU:\t43.00%\r\n",
      "CPU:\t6.80%\t|Mem:\t22.00%\t|GPU:\t39.00%\r\n",
      "CPU:\t7.00%\t|Mem:\t22.00%\t|GPU:\t42.00%\r\n",
      "CPU:\t5.10%\t|Mem:\t21.60%\t|GPU:\t0.00%\r\n",
      "CPU times: user 8.7 s, sys: 1.45 s, total: 10.1 s\r\n",
      "Wall time: 19min 2s\r\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "! python 3.moni.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 ERNIE-4.5-0.3B-INT8\n",
    "\n",
    "* **启动服务**\n",
    "\n",
    "```shell\n",
    "sh 1.server-int8.sh &\n",
    "```\n",
    "\n",
    "* **开始评测**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T12:52:19.248777Z",
     "iopub.status.busy": "2025-12-31T12:52:19.248519Z",
     "iopub.status.idle": "2025-12-31T12:52:19.469230Z",
     "shell.execute_reply": "2025-12-31T12:52:19.468477Z",
     "shell.execute_reply.started": "2025-12-31T12:52:19.248757Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "clear\r\n",
      "path=/home/aistudio/data/models\r\n",
      "model=ERNIE-4.5-0.3B-Base-Paddle\r\n",
      "\r\n",
      "python -m fastdeploy.entrypoints.openai.api_server --model $path/$model --port 8180 --metrics-port 8181 --engine-worker-queue-port 8182 --max-model-len 3072 --max-num-seqs 128 --quantization wint8\r\n"
     ]
    }
   ],
   "source": [
    "! cat 1.server-int8.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T09:41:30.603385Z",
     "iopub.status.busy": "2025-12-31T09:41:30.603121Z",
     "iopub.status.idle": "2025-12-31T09:59:33.620591Z",
     "shell.execute_reply": "2025-12-31T09:59:33.619651Z",
     "shell.execute_reply.started": "2025-12-31T09:41:30.603365Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU:\t5.30%\t|Mem:\t21.90%\t|GPU:\t0.00%\r\n",
      "CPU:\t6.10%\t|Mem:\t21.90%\t|GPU:\t48.00%\r\n",
      "CPU:\t7.30%\t|Mem:\t21.90%\t|GPU:\t48.00%\r\n",
      "CPU:\t7.10%\t|Mem:\t21.90%\t|GPU:\t44.00%\r\n",
      "CPU:\t12.00%\t|Mem:\t21.90%\t|GPU:\t48.00%\r\n",
      "CPU:\t7.60%\t|Mem:\t21.90%\t|GPU:\t44.00%\r\n",
      "CPU:\t6.60%\t|Mem:\t21.90%\t|GPU:\t48.00%\r\n",
      "CPU:\t7.10%\t|Mem:\t21.90%\t|GPU:\t44.00%\r\n",
      "CPU:\t8.20%\t|Mem:\t22.00%\t|GPU:\t44.00%\r\n",
      "CPU:\t14.30%\t|Mem:\t22.00%\t|GPU:\t45.00%\r\n",
      "CPU:\t8.00%\t|Mem:\t22.00%\t|GPU:\t46.00%\r\n",
      "CPU:\t6.20%\t|Mem:\t22.00%\t|GPU:\t45.00%\r\n",
      "CPU:\t16.50%\t|Mem:\t22.00%\t|GPU:\t49.00%\r\n",
      "CPU:\t10.30%\t|Mem:\t22.00%\t|GPU:\t43.00%\r\n",
      "CPU:\t8.10%\t|Mem:\t22.00%\t|GPU:\t48.00%\r\n",
      "CPU:\t8.10%\t|Mem:\t22.00%\t|GPU:\t46.00%\r\n",
      "CPU:\t5.90%\t|Mem:\t22.00%\t|GPU:\t47.00%\r\n",
      "CPU:\t15.50%\t|Mem:\t22.00%\t|GPU:\t46.00%\r\n",
      "CPU:\t5.20%\t|Mem:\t21.90%\t|GPU:\t0.00%\r\n",
      "CPU times: user 8.03 s, sys: 1.5 s, total: 9.53 s\r\n",
      "Wall time: 18min 3s\r\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "! python 3.moni.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 ERNIE-4.5-0.3B-INT4\n",
    "\n",
    "* **启动服务**\n",
    "\n",
    "```shell\n",
    "sh 1.server-int4.sh &\n",
    "```\n",
    "\n",
    "* **开始评测**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T12:52:23.291375Z",
     "iopub.status.busy": "2025-12-31T12:52:23.291118Z",
     "iopub.status.idle": "2025-12-31T12:52:23.512413Z",
     "shell.execute_reply": "2025-12-31T12:52:23.511585Z",
     "shell.execute_reply.started": "2025-12-31T12:52:23.291355Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "clear\r\n",
      "path=/home/aistudio/data/models\r\n",
      "model=ERNIE-4.5-0.3B-Base-Paddle\r\n",
      "\r\n",
      "python -m fastdeploy.entrypoints.openai.api_server --model $path/$model --port 8180 --metrics-port 8181 --engine-worker-queue-port 8182 --max-model-len 3072 --max-num-seqs 128 --quantization wint4\r\n"
     ]
    }
   ],
   "source": [
    "! cat 1.server-int4.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T10:05:11.273657Z",
     "iopub.status.busy": "2025-12-31T10:05:11.273414Z",
     "iopub.status.idle": "2025-12-31T10:23:14.295251Z",
     "shell.execute_reply": "2025-12-31T10:23:14.294329Z",
     "shell.execute_reply.started": "2025-12-31T10:05:11.273637Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU:\t6.80%\t|Mem:\t21.80%\t|GPU:\t0.00%\r\n",
      "CPU:\t8.80%\t|Mem:\t21.90%\t|GPU:\t43.00%\r\n",
      "CPU:\t6.50%\t|Mem:\t21.90%\t|GPU:\t50.00%\r\n",
      "CPU:\t8.50%\t|Mem:\t21.90%\t|GPU:\t49.00%\r\n",
      "CPU:\t7.40%\t|Mem:\t21.90%\t|GPU:\t44.00%\r\n",
      "CPU:\t7.00%\t|Mem:\t21.90%\t|GPU:\t47.00%\r\n",
      "CPU:\t7.90%\t|Mem:\t21.90%\t|GPU:\t47.00%\r\n",
      "CPU:\t13.50%\t|Mem:\t21.90%\t|GPU:\t42.00%\r\n",
      "CPU:\t6.70%\t|Mem:\t21.90%\t|GPU:\t46.00%\r\n",
      "CPU:\t6.50%\t|Mem:\t21.90%\t|GPU:\t46.00%\r\n",
      "CPU:\t7.10%\t|Mem:\t22.00%\t|GPU:\t47.00%\r\n",
      "CPU:\t7.60%\t|Mem:\t21.90%\t|GPU:\t50.00%\r\n",
      "CPU:\t12.30%\t|Mem:\t21.90%\t|GPU:\t47.00%\r\n",
      "CPU:\t7.30%\t|Mem:\t22.00%\t|GPU:\t45.00%\r\n",
      "CPU:\t6.60%\t|Mem:\t22.00%\t|GPU:\t51.00%\r\n",
      "CPU:\t14.90%\t|Mem:\t22.00%\t|GPU:\t47.00%\r\n",
      "CPU:\t7.50%\t|Mem:\t22.00%\t|GPU:\t47.00%\r\n",
      "CPU:\t7.90%\t|Mem:\t22.00%\t|GPU:\t48.00%\r\n",
      "CPU:\t7.50%\t|Mem:\t21.90%\t|GPU:\t0.00%\r\n",
      "CPU times: user 8.77 s, sys: 1.48 s, total: 10.2 s\r\n",
      "Wall time: 18min 3s\r\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "! python 3.moni.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 ERNIE-4.5-0.3B-INT2\n",
    "\n",
    "* **启动服务**\n",
    "\n",
    "```shell\n",
    "sh 1.server-int2.sh &\n",
    "```\n",
    "\n",
    "* **开始评测**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T12:52:26.786140Z",
     "iopub.status.busy": "2025-12-31T12:52:26.785888Z",
     "iopub.status.idle": "2025-12-31T12:52:27.018277Z",
     "shell.execute_reply": "2025-12-31T12:52:27.017372Z",
     "shell.execute_reply.started": "2025-12-31T12:52:26.786121Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "clear\r\n",
      "path=/home/aistudio/data/models\r\n",
      "model=ERNIE-4.5-0.3B-Base-Paddle\r\n",
      "\r\n",
      "python -m fastdeploy.entrypoints.openai.api_server --model $path/$model --port 8180 --metrics-port 8181 --engine-worker-queue-port 8182 --max-model-len 3072 --max-num-seqs 128 --quantization wint2\r\n"
     ]
    }
   ],
   "source": [
    "! cat 1.server-int2.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T10:25:40.303268Z",
     "iopub.status.busy": "2025-12-31T10:25:40.303014Z",
     "iopub.status.idle": "2025-12-31T10:44:43.512686Z",
     "shell.execute_reply": "2025-12-31T10:44:43.511751Z",
     "shell.execute_reply.started": "2025-12-31T10:25:40.303248Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU:\t6.80%\t|Mem:\t21.90%\t|GPU:\t0.00%\r\n",
      "CPU:\t8.30%\t|Mem:\t22.00%\t|GPU:\t41.00%\r\n",
      "CPU:\t13.10%\t|Mem:\t22.00%\t|GPU:\t39.00%\r\n",
      "CPU:\t8.50%\t|Mem:\t22.00%\t|GPU:\t39.00%\r\n",
      "CPU:\t6.50%\t|Mem:\t22.00%\t|GPU:\t43.00%\r\n",
      "CPU:\t7.30%\t|Mem:\t22.00%\t|GPU:\t44.00%\r\n",
      "CPU:\t7.30%\t|Mem:\t22.00%\t|GPU:\t41.00%\r\n",
      "CPU:\t7.40%\t|Mem:\t22.00%\t|GPU:\t44.00%\r\n",
      "CPU:\t9.40%\t|Mem:\t22.00%\t|GPU:\t40.00%\r\n",
      "CPU:\t7.40%\t|Mem:\t22.00%\t|GPU:\t40.00%\r\n",
      "CPU:\t7.50%\t|Mem:\t22.00%\t|GPU:\t42.00%\r\n",
      "CPU:\t6.70%\t|Mem:\t22.00%\t|GPU:\t44.00%\r\n",
      "CPU:\t6.90%\t|Mem:\t22.00%\t|GPU:\t41.00%\r\n",
      "CPU:\t8.00%\t|Mem:\t22.00%\t|GPU:\t45.00%\r\n",
      "CPU:\t7.90%\t|Mem:\t22.00%\t|GPU:\t36.00%\r\n",
      "CPU:\t6.90%\t|Mem:\t22.00%\t|GPU:\t45.00%\r\n",
      "CPU:\t5.70%\t|Mem:\t22.00%\t|GPU:\t44.00%\r\n",
      "CPU:\t7.20%\t|Mem:\t22.00%\t|GPU:\t44.00%\r\n",
      "CPU:\t11.50%\t|Mem:\t22.00%\t|GPU:\t47.00%\r\n",
      "CPU:\t6.60%\t|Mem:\t21.90%\t|GPU:\t0.00%\r\n",
      "CPU times: user 8.76 s, sys: 1.59 s, total: 10.4 s\r\n",
      "Wall time: 19min 3s\r\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "! python 3.moni.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、评测结果\n",
    "\n",
    "### 4.1 实验数据\n",
    "\n",
    "|                                    |        BASE|        INT8|        INT4|        INT2|\n",
    "|------------------------------------|------------|------------|------------|------------|\n",
    "| score                              |   48.329   |   48.591   | **49.258** |   48.620   |\n",
    "| OPPO                               |   46.475   |   46.315   |   46.255   | **49.785** |\n",
    "| DuQM_pos                           |   46.201   |   45.482   | **46.288** |   55.759   |\n",
    "| DuQM_named_entity                  |   54.265   |   53.529   |   51.250   | **58.456** |\n",
    "| DuQM_synonym                       |   51.194   |   51.592   | **53.981** |   43.312   |\n",
    "| DuQM_antonym                       |   31.148   |   35.082   |   38.361   | **50.164** |\n",
    "| DuQM_negation                      |   44.160   |   45.584   |   40.456   | **49.003** |\n",
    "| DuQM_temporal                      |   48.718   |   40.598   |   39.744   | **53.419** |\n",
    "| DuQM_symmetry                      |   60.225   | **61.351** |   60.976   |   51.595   |\n",
    "| DuQM_asymmetry                     |   43.058   |   43.662   |   45.272   | **50.704** |\n",
    "| DuQM_neg_asymmetry                 |   46.939   |   48.980   | **57.143** |   42.857   |\n",
    "| DuQM_voice                         |   49.618   |   50.382   | **53.435** |   46.565   |\n",
    "| DuQM_misspelling                   | **48.291** |   47.650   |   46.795   |   39.957   |\n",
    "| DuQM_discourse_particle(simple)    | **58.216** |   55.869   |   57.746   |   47.887   |\n",
    "| DuQM_discourse_particle(complex)   |   48.092   | **54.198** |   51.908   |   41.221   |\n",
    "\n",
    "### 4.2 评测总结\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T12:52:31.715891Z",
     "iopub.status.busy": "2025-12-31T12:52:31.715635Z",
     "iopub.status.idle": "2025-12-31T12:52:31.792400Z",
     "shell.execute_reply": "2025-12-31T12:52:31.791776Z",
     "shell.execute_reply.started": "2025-12-31T12:52:31.715871Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                      <span style=\"font-weight: bold\">一、整体性能表现：量化模型的潜力与局限</span>                                       \n",
       "\n",
       "在总分维度，INT4模型以<span style=\"font-weight: bold\">49.258分</span>微弱领先（BASE:48.329, INT8:48.591,                                                  \n",
       "INT2:48.620），表明中等精度量化（4比特）在综合场景下可能实现最优平衡。值得注意的是：                               \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">低比特模型的波动性</span>：INT2虽总分排名末位，却在OPPO真实对话场景以<span style=\"font-weight: bold\">49.785分</span>显著反超其他模型（领先INT4达3.53分），揭示\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>低比特量化在特定场景的潜在优势；                                                                                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">量化收益非线性</span>：INT8相比BASE提升0.26分，但INT4较INT8再提升0.67分，说明4比特可能是该系列模型的\"甜点\"精度。       \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                   <span style=\"font-weight: bold\">二、场景化能力解析：量化对语义扰动敏感度分化</span>                                    \n",
       "\n",
       "                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">1. 优势场景：低比特量化展现特殊鲁棒性</span>                                       \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">逻辑反转任务</span>：INT2在反义词(DuQM_antonym)测试中以<span style=\"font-weight: bold\">50.164分</span>碾压式领先（较BASE提升19分），在否定句(DuQM_negation)和 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>时间扰动(DuQM_temporal)也分别提升4.84分和4.7分，表明极低精度可能增强模型对逻辑结构变化的抵抗力；                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">实体泛化能力</span>：INT2在命名实体替换(DuQM_named_entity)中以<span style=\"font-weight: bold\">58.456分</span>创全场最高记录（超BASE                           \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>4.19分），证明其对实体指代一致性具有独特处理机制；                                                              \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">非对称关系理解</span>：INT2在不对称关系(DuQM_asymmetry)得分<span style=\"font-weight: bold\">50.704分</span>（较BASE提升7.6分），INT4在否定不对称(DuQM_neg_asymm\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>etry)以<span style=\"font-weight: bold\">57.143分</span>领先10.2分，显示量化可能优化复杂关系推理。                                                       \n",
       "\n",
       "                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">2. 劣势场景：精度损失暴露模型脆弱性</span>                                        \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">语法结构敏感度</span>：INT2在语态变换(DuQM_voice)得分<span style=\"font-weight: bold\">46.565分</span>（低于INT4近7分），在拼写错误(DuQM_misspelling)暴跌至<span style=\"font-weight: bold\">39.95</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span><span style=\"font-weight: bold\">7分</span>（较BASE损失8.33分），暴露低比特模型对表层语言特征适应性差；                                                 \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">连接词理解障碍</span>：INT2在复杂话语粒子(DuQM_discourse_particle(complex))测试仅得<span style=\"font-weight: bold\">41.221分</span>（较最佳INT8低13分），显示其\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>对逻辑连接词的解析能力严重退化；                                                                                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">语义一致性挑战</span>：INT4虽在近义词(DuQM_synonym)以<span style=\"font-weight: bold\">53.981分</span>领先，但在命名实体测试却跌至<span style=\"font-weight: bold\">51.25分</span>（低于BASE             \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>3分），表明其语义保持能力存在不稳定波动。                                                                       \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                              <span style=\"font-weight: bold\">三、技术启示与落地建议</span>                                               \n",
       "\n",
       "                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">1. 量化策略需场景定制化</span>                                              \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>对话系统(如OPPO场景)优先考虑INT2（真实对话得分<span style=\"font-weight: bold\">49.785</span>），其压缩特性可能更适配口语化短文本；                      \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>搜索问答场景推荐INT4（总分<span style=\"font-weight: bold\">49.258</span>），尤其在近义词、语态变换等任务保持稳健性；                                    \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>高精度要求场景（如拼写纠错、学术文本）仍需保留BASE模型。                                                        \n",
       "\n",
       "                                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">2. 关键发现对模型优化的启示</span>                                            \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">比特深度与语义层级的关联</span>：低比特(INT2)在深层逻辑任务（反义/否定）表现突出，而在表层语言任务（拼写/连接词）严重滑\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>坡，建议研发分层量化策略——对逻辑层采用激进量化，对词法层保留较高精度；                                          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">量化噪声的双面性</span>：INT2在时间扰动测试的异常提升（<span style=\"font-weight: bold\">53.419分</span> vs BASE                                                \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>48.718）暗示适度噪声可能增强时序泛化能力，可通过可控噪声注入提升鲁棒性；                                        \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span><span style=\"font-weight: bold\">领域数据差异性</span>：OPPO对话数据与DuQM人工扰动数据呈现相反趋势（INT2在OPPO领先3.5分，在DuQM总分落后0.6分），强调部署\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>前必须进行领域适配验证。                                                                                        \n",
       "\n",
       "                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">3. 工程落地风险预警</span>                                                \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>警惕<span style=\"font-weight: bold\">量化放大系统性偏差</span>：INT2在反义词测试的陡升（+19分）与近义词测试的崩塌（43.312分 vs INT4                     \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>53.981分）形成危险反差，需严格测试语义一致性；                                                                  \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> • </span>规避<span style=\"font-weight: bold\">场景错配风险</span>：在客服系统等需处理拼写错误的场景禁用INT2（拼写测试仅39.957分），而在智能合约审查等逻辑敏感场景\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>可尝试部署。                                                                                                    \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "                                                   <span style=\"font-weight: bold\">四、前瞻方向</span>                                                    \n",
       "\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 1 </span><span style=\"font-weight: bold\">动态比特分配</span>：根据输入文本特征（如检测到反义词对时自动切换低比特模式）实现精度自适应；                          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 2 </span><span style=\"font-weight: bold\">扰动感知训练</span>：在量化训练阶段针对性加入反义词替换、时间扰动等对抗样本；                                          \n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> 3 </span><span style=\"font-weight: bold\">混合精度架构</span>：核心逻辑模块采用INT2，语言表层处理模块保留INT8以上精度。                                          \n",
       "\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">▌ 总结：量化不是简单的精度折衷，而是重塑模型能力分布的过程。本次测试表明，</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">INT4可实现最佳综合平衡，而INT2在特定逻</span><span style=\"color: #800080; text-decoration-color: #800080\"> </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">▌ </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">辑推理场景展现颠覆性优势</span><span style=\"color: #800080; text-decoration-color: #800080\">。技术团队需建立\"场景-量化精度-能力图谱\"的对应关系，在7%的精度波动区间内进行精细化策略 </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">▌ 设计，方能在压缩与性能的博弈中实现最优解。未来突破点在于解构神经网络各层对量化的敏感度，实现神经元级的动态精度 </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">▌ 调控。                                                                                                         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                      \u001b[1m一、整体性能表现：量化模型的潜力与局限\u001b[0m                                       \n",
       "\n",
       "在总分维度，INT4模型以\u001b[1m49.258分\u001b[0m微弱领先（BASE:48.329, INT8:48.591,                                                  \n",
       "INT2:48.620），表明中等精度量化（4比特）在综合场景下可能实现最优平衡。值得注意的是：                               \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1m低比特模型的波动性\u001b[0m：INT2虽总分排名末位，却在OPPO真实对话场景以\u001b[1m49.785分\u001b[0m显著反超其他模型（领先INT4达3.53分），揭示\n",
       "\u001b[1;33m   \u001b[0m低比特量化在特定场景的潜在优势；                                                                                \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m量化收益非线性\u001b[0m：INT8相比BASE提升0.26分，但INT4较INT8再提升0.67分，说明4比特可能是该系列模型的\"甜点\"精度。       \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                   \u001b[1m二、场景化能力解析：量化对语义扰动敏感度分化\u001b[0m                                    \n",
       "\n",
       "                                       \u001b[1;2m1. \u001b[0m\u001b[1;2m优势场景：低比特量化展现特殊鲁棒性\u001b[0m                                       \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1m逻辑反转任务\u001b[0m：INT2在反义词(DuQM_antonym)测试中以\u001b[1m50.164分\u001b[0m碾压式领先（较BASE提升19分），在否定句(DuQM_negation)和 \n",
       "\u001b[1;33m   \u001b[0m时间扰动(DuQM_temporal)也分别提升4.84分和4.7分，表明极低精度可能增强模型对逻辑结构变化的抵抗力；                \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m实体泛化能力\u001b[0m：INT2在命名实体替换(DuQM_named_entity)中以\u001b[1m58.456分\u001b[0m创全场最高记录（超BASE                           \n",
       "\u001b[1;33m   \u001b[0m4.19分），证明其对实体指代一致性具有独特处理机制；                                                              \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m非对称关系理解\u001b[0m：INT2在不对称关系(DuQM_asymmetry)得分\u001b[1m50.704分\u001b[0m（较BASE提升7.6分），INT4在否定不对称(DuQM_neg_asymm\n",
       "\u001b[1;33m   \u001b[0metry)以\u001b[1m57.143分\u001b[0m领先10.2分，显示量化可能优化复杂关系推理。                                                       \n",
       "\n",
       "                                        \u001b[1;2m2. \u001b[0m\u001b[1;2m劣势场景：精度损失暴露模型脆弱性\u001b[0m                                        \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1m语法结构敏感度\u001b[0m：INT2在语态变换(DuQM_voice)得分\u001b[1m46.565分\u001b[0m（低于INT4近7分），在拼写错误(DuQM_misspelling)暴跌至\u001b[1m39.95\u001b[0m\n",
       "\u001b[1;33m   \u001b[0m\u001b[1m7分\u001b[0m（较BASE损失8.33分），暴露低比特模型对表层语言特征适应性差；                                                 \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m连接词理解障碍\u001b[0m：INT2在复杂话语粒子(DuQM_discourse_particle(complex))测试仅得\u001b[1m41.221分\u001b[0m（较最佳INT8低13分），显示其\n",
       "\u001b[1;33m   \u001b[0m对逻辑连接词的解析能力严重退化；                                                                                \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m语义一致性挑战\u001b[0m：INT4虽在近义词(DuQM_synonym)以\u001b[1m53.981分\u001b[0m领先，但在命名实体测试却跌至\u001b[1m51.25分\u001b[0m（低于BASE             \n",
       "\u001b[1;33m   \u001b[0m3分），表明其语义保持能力存在不稳定波动。                                                                       \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                              \u001b[1m三、技术启示与落地建议\u001b[0m                                               \n",
       "\n",
       "                                              \u001b[1;2m1. \u001b[0m\u001b[1;2m量化策略需场景定制化\u001b[0m                                              \n",
       "\n",
       "\u001b[1;33m • \u001b[0m对话系统(如OPPO场景)优先考虑INT2（真实对话得分\u001b[1m49.785\u001b[0m），其压缩特性可能更适配口语化短文本；                      \n",
       "\u001b[1;33m • \u001b[0m搜索问答场景推荐INT4（总分\u001b[1m49.258\u001b[0m），尤其在近义词、语态变换等任务保持稳健性；                                    \n",
       "\u001b[1;33m • \u001b[0m高精度要求场景（如拼写纠错、学术文本）仍需保留BASE模型。                                                        \n",
       "\n",
       "                                            \u001b[1;2m2. 关键发现对模型优化的启示\u001b[0m                                            \n",
       "\n",
       "\u001b[1;33m • \u001b[0m\u001b[1m比特深度与语义层级的关联\u001b[0m：低比特(INT2)在深层逻辑任务（反义/否定）表现突出，而在表层语言任务（拼写/连接词）严重滑\n",
       "\u001b[1;33m   \u001b[0m坡，建议研发分层量化策略——对逻辑层采用激进量化，对词法层保留较高精度；                                          \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m量化噪声的双面性\u001b[0m：INT2在时间扰动测试的异常提升（\u001b[1m53.419分\u001b[0m vs BASE                                                \n",
       "\u001b[1;33m   \u001b[0m48.718）暗示适度噪声可能增强时序泛化能力，可通过可控噪声注入提升鲁棒性；                                        \n",
       "\u001b[1;33m • \u001b[0m\u001b[1m领域数据差异性\u001b[0m：OPPO对话数据与DuQM人工扰动数据呈现相反趋势（INT2在OPPO领先3.5分，在DuQM总分落后0.6分），强调部署\n",
       "\u001b[1;33m   \u001b[0m前必须进行领域适配验证。                                                                                        \n",
       "\n",
       "                                                \u001b[1;2m3. 工程落地风险预警\u001b[0m                                                \n",
       "\n",
       "\u001b[1;33m • \u001b[0m警惕\u001b[1m量化放大系统性偏差\u001b[0m：INT2在反义词测试的陡升（+19分）与近义词测试的崩塌（43.312分 vs INT4                     \n",
       "\u001b[1;33m   \u001b[0m53.981分）形成危险反差，需严格测试语义一致性；                                                                  \n",
       "\u001b[1;33m • \u001b[0m规避\u001b[1m场景错配风险\u001b[0m：在客服系统等需处理拼写错误的场景禁用INT2（拼写测试仅39.957分），而在智能合约审查等逻辑敏感场景\n",
       "\u001b[1;33m   \u001b[0m可尝试部署。                                                                                                    \n",
       "\n",
       "\u001b[33m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
       "                                                   \u001b[1m四、前瞻方向\u001b[0m                                                    \n",
       "\n",
       "\u001b[1;33m 1 \u001b[0m\u001b[1m动态比特分配\u001b[0m：根据输入文本特征（如检测到反义词对时自动切换低比特模式）实现精度自适应；                          \n",
       "\u001b[1;33m 2 \u001b[0m\u001b[1m扰动感知训练\u001b[0m：在量化训练阶段针对性加入反义词替换、时间扰动等对抗样本；                                          \n",
       "\u001b[1;33m 3 \u001b[0m\u001b[1m混合精度架构\u001b[0m：核心逻辑模块采用INT2，语言表层处理模块保留INT8以上精度。                                          \n",
       "\n",
       "\u001b[35m▌ \u001b[0m\u001b[35m总结：量化不是简单的精度折衷，而是重塑模型能力分布的过程。本次测试表明，\u001b[0m\u001b[1;35mINT4可实现最佳综合平衡，而INT2在特定逻\u001b[0m\u001b[35m \u001b[0m\n",
       "\u001b[35m▌ \u001b[0m\u001b[1;35m辑推理场景展现颠覆性优势\u001b[0m\u001b[35m。技术团队需建立\"场景-量化精度-能力图谱\"的对应关系，在7%的精度波动区间内进行精细化策略\u001b[0m\u001b[35m \u001b[0m\n",
       "\u001b[35m▌ \u001b[0m\u001b[35m设计，方能在压缩与性能的博弈中实现最优解。未来突破点在于解构神经网络各层对量化的敏感度，实现神经元级的动态精度\u001b[0m\u001b[35m \u001b[0m\n",
       "\u001b[35m▌ \u001b[0m\u001b[35m调控。\u001b[0m\u001b[35m                                                                                                         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# pip install rich\n",
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "\n",
    "console = Console()\n",
    "\n",
    "result = \"\"\n",
    "with open(\"4.result.log\", \"r\") as f:\n",
    "    for i in f:\n",
    "        result += i\n",
    "console.print(Markdown(result))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
